{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, shutil\noriginal_dataset_dir = '/kaggle/input/plant-seedlings-classification'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras.models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/base'\nos.mkdir(base_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Black_grass_dir = os.path.join(train_dir, 'Black-grass')\ntrain_Charlock_dir = os.path.join(train_dir, 'Charlock')\ntrain_Cleavers_dir = os.path.join(train_dir, 'Cleavers')\ntrain_Common_Chickweed_dir = os.path.join(train_dir, 'Common Chickweed')\ntrain_Common_wheat_dir = os.path.join(train_dir, 'Common wheat')\ntrain_Fat_Hen_dir = os.path.join(train_dir, 'Fat Hen')\ntrain_Loose_Silky_bent_dir = os.path.join(train_dir, 'Loose Silky-bent')\ntrain_Maize_dir = os.path.join(train_dir, 'Maize')\ntrain_Scentless_Mayweed_dir = os.path.join(train_dir, 'Scentless Mayweed')\ntrain_Shepherds_Purse_dir = os.path.join(train_dir, 'Shepherds Purse')\ntrain_Small_flowered_Cranesbill_dir = os.path.join(train_dir, 'Small-flowered Cranesbill')\ntrain_Sugar_beet_dir = os.path.join(train_dir, 'Sugar beet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(train_Black_grass_dir)\nos.mkdir(train_Charlock_dir)\nos.mkdir(train_Cleavers_dir)\nos.mkdir(train_Common_Chickweed_dir)\nos.mkdir(train_Common_wheat_dir)\nos.mkdir(train_Fat_Hen_dir)\nos.mkdir(train_Loose_Silky_bent_dir)\nos.mkdir(train_Maize_dir)\nos.mkdir(train_Scentless_Mayweed_dir)\nos.mkdir(train_Shepherds_Purse_dir)\nos.mkdir(train_Small_flowered_Cranesbill_dir)\nos.mkdir(train_Sugar_beet_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_Black_grass_dir = os.path.join(validation_dir, 'Black-grass')\nvalidation_Charlock_dir = os.path.join(validation_dir, 'Charlock')\nvalidation_Cleavers_dir = os.path.join(validation_dir, 'Cleavers')\nvalidation_Common_Chickweed_dir = os.path.join(validation_dir, 'Common Chickweed')\nvalidation_Common_wheat_dir = os.path.join(validation_dir, 'Common wheat')\nvalidation_Fat_Hen_dir = os.path.join(validation_dir, 'Fat Hen')\nvalidation_Loose_Silky_bent_dir = os.path.join(validation_dir, 'Loose Silky-bent')\nvalidation_Maize_dir = os.path.join(validation_dir, 'Maize')\nvalidation_Scentless_Mayweed_dir = os.path.join(validation_dir, 'Scentless Mayweed')\nvalidation_Shepherds_Purse_dir = os.path.join(validation_dir, 'Shepherds Purse')\nvalidation_Small_flowered_Cranesbill_dir = os.path.join(validation_dir, 'Small-flowered Cranesbill')\nvalidation_Sugar_beet_dir = os.path.join(validation_dir, 'Sugar beet')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(validation_Black_grass_dir)\nos.mkdir(validation_Charlock_dir)\nos.mkdir(validation_Cleavers_dir)\nos.mkdir(validation_Common_Chickweed_dir)\nos.mkdir(validation_Common_wheat_dir)\nos.mkdir(validation_Fat_Hen_dir)\nos.mkdir(validation_Loose_Silky_bent_dir)\nos.mkdir(validation_Maize_dir)\nos.mkdir(validation_Scentless_Mayweed_dir)\nos.mkdir(validation_Shepherds_Purse_dir)\nos.mkdir(validation_Small_flowered_Cranesbill_dir)\nos.mkdir(validation_Sugar_beet_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil \nimport os \n\nfor file_dir in os.listdir('/kaggle/input/plant-seedlings-classification/train'):\n    l = int(len(os.listdir('/kaggle/input/plant-seedlings-classification/train/'+file_dir))*0.7)\n    count = 0\n    for img in os.listdir('/kaggle/input/plant-seedlings-classification/train/'+file_dir):\n        if img.endswith(\".png\"):\n            if count < l:\n                src_dir = \"/kaggle/input/plant-seedlings-classification/train/\"+file_dir+'/'+img\n                dst_dir = train_dir+'/'+(os.path.basename(os.path.normpath(file_dir)))\n                count += 1\n                shutil.copy(src_dir,dst_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in os.listdir('/kaggle/input/plant-seedlings-classification/test'):\n    if img.endswith(\".png\"):\n        src = '/kaggle/input/plant-seedlings-classification/test/'+ img\n        dst = '/kaggle/input/base/test'\n        shutil.copy(src,dst)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input/base/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for file_dir in os.listdir('/kaggle/input/plant-seedlings-classification/train'):\n    l = int(len(os.listdir('/kaggle/input/plant-seedlings-classification/train/'+file_dir))*0.7)\n    count = 0\n#     print (l)\n    for img in os.listdir('/kaggle/input/plant-seedlings-classification/train/'+file_dir):\n        if img.endswith(\".png\"):\n            if count >= l:\n                src_dir = \"/kaggle/input/plant-seedlings-classification/train/\"+file_dir+'/'+img\n                dst_dir = validation_dir+'/'+(os.path.basename(os.path.normpath(file_dir)))\n#                 print (count)\n                shutil.copy(src_dir,dst_dir)\n            count += 1\n            \n#                 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('total training cat images:', len(os.listdir(train_Black_grass_dir)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor dirs in os.listdir(validation_dir):\n    for img in os.listdir(validation_dir+'/'+dirs):\n        i += 1\nprint (i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir('/kaggle/input/plant-seedlings-classification/train/Black-grass'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n\nim = Image.open('/kaggle/input/plant-seedlings-classification/train/Black-grass/d3c72d4c3.png')\nwidth, height = im.size\nprint (width)\nprint (height)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_class = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras.layers.core import Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',\ninput_shape=(84, 84, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(layers.Dense(12, activation='softmax'))\n# model.add(Activation(activation='softmax'))\n# model.add(layers.Dense(12, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\nmodel.compile(loss='categorical_crossentropy',\n                optimizer=optimizers.RMSprop(lr=1e-4),\n                metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_directory(\n                train_dir,\n                target_size=(84, 84),\n                batch_size=20,\n                class_mode='categorical')\nvalidation_generator = test_datagen.flow_from_directory(\n                validation_dir,\n                target_size=(84, 84),\n                batch_size=20,\n                class_mode='categorical')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data_batch, labels_batch in train_generator:\n    print('data batch shape:', data_batch.shape)\n    print('labels batch shape:', labels_batch.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"simple ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(\n            train_generator,\n            steps_per_epoch=100,\n            epochs=10,\n            validation_data=validation_generator,\n            validation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/input/simple.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\nrotation_range=40,\nwidth_shift_range=0.2,\nheight_shift_range=0.2,\nshear_range=0.2,\nzoom_range=0.2,\nhorizontal_flip=True,\nfill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras.layers.core import Activation\nfrom keras.layers import BatchNormalization\nfrom keras.layers import Dropout\nfrom keras import optimizers\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu',\ninput_shape=(84, 84, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(12, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',\noptimizer=optimizers.RMSprop(lr=1e-4),\nmetrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\nrescale=1./255,\nrotation_range=40,\nwidth_shift_range=0.2,\nheight_shift_range=0.2,\nshear_range=0.2,\nzoom_range=0.2,\nhorizontal_flip=True,)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(84, 84),\nbatch_size=32,\nclass_mode='categorical')\nvalidation_generator = test_datagen.flow_from_directory(\nvalidation_dir,\ntarget_size=(84, 84),\nbatch_size=32,\nclass_mode='categorical')\n\n\nhistory = model.fit_generator(\ntrain_generator,\nsteps_per_epoch=100,\nepochs=30,\nvalidation_data=validation_generator,\nvalidation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/input/simple_augmentation.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\nconv_base = VGG16(weights='imagenet',\ninclude_top=False,\ninput_shape=(84, 84, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" conv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(12, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Fine tuning "},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\ntrain_datagen = ImageDataGenerator(\nrescale=1./255,\nrotation_range=40,\nwidth_shift_range=0.2,\nheight_shift_range=0.2,\nshear_range=0.2,\nzoom_range=0.2,\nhorizontal_flip=True,\nfill_mode='nearest')\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\ntrain_dir,\ntarget_size=(84, 84),\nbatch_size=20,\nclass_mode='categorical')\nvalidation_generator = test_datagen.flow_from_directory(\nvalidation_dir,\ntarget_size=(84, 84),\nbatch_size=20,\nclass_mode='categorical')\nmodel.compile(loss='categorical_crossentropy',\noptimizer=optimizers.RMSprop(lr=2e-5),\nmetrics=['acc'])\n\nhistory = model.fit_generator(\ntrain_generator,\nsteps_per_epoch=100,\nepochs=50,\nvalidation_data=validation_generator,\nvalidation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base.trainable = True\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\noptimizer=optimizers.RMSprop(lr=1e-5),\nmetrics=['acc'])\nhistory = model.fit_generator(\ntrain_generator,\nsteps_per_epoch=100,\nepochs=50,\nvalidation_data=validation_generator,\nvalidation_steps=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"/kaggle/input/fine_tuned.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'finalized_model.sav'\npickle.dump(model, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(\nvalidation_dir,\ntarget_size=(84, 84),\nbatch_size=20,\nclass_mode='categorical')\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('/kaggle/input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/plant-seedlings-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nfrom keras.preprocessing import image\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef load_image(img_path, show=False):\n    img = image.load_img(img_path, target_size=(84, 84))\n    img_tensor = image.img_to_array(img)\n    img_tensor = np.expand_dims(img_tensor, axis=0)\n    img_tensor /= 255.\n    return img_tensor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 84, 84\nmodel = load_model('/kaggle/input/fine_tuned.h5')\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_dict = train_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"key_list = list(my_dict.keys()) \nval_list = list(my_dict.values()) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('/kaggle/input/fine_tuned.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nfor sub_img in submission['file']:\n    img_path = test_dir+'/'+sub_img\n    print (img_path)\n    new_image = load_image(img_path)\n    pred = model.predict(new_image)\n    labels = np.argmax(pred, axis=-1)  \n    name = key_list[val_list.index(labels)]\n    print (name)\n    submission['species'][count] = name\n    count += 1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['species'][793]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}